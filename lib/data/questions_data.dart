import '../models/listening_question.dart';

final List<ListeningQuestion> listeningQuestions = [
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10001.wav',
    imagePath: 'images/cefr_a10001.png',
    englishText: 'My name is John and I am from Japan.',
  ),
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10002.wav',
    imagePath: 'images/cefr_a10002.png',
    englishText: 'I have a cat and a dog.',
  ),
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10003.wav',
    imagePath: 'images/cefr_a10003.png',
    englishText: 'I like to eat and sleep.',
  ),
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10004.wav',
    imagePath: 'images/cefr_a10004.png',
    englishText: 'The sky is blue.',
  ),
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10005.wav',
    imagePath: 'images/cefr_a10005.png',
    englishText: 'I go to the park every day.',
  ),
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10006.wav',
    imagePath: 'images/cefr_a10006.png',
    englishText: 'She is reading a book.',
  ),
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10007.wav',
    imagePath: 'images/cefr_a10007.png',
    englishText: 'He drinks hot coffee.',
  ),
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10008.wav',
    imagePath: 'images/cefr_a10008.png',
    englishText: 'They are playing in the garden.',
  ),
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10009.wav',
    imagePath: 'images/cefr_a10009.png',
    englishText: 'It is a sunny and hot day.',
  ),
  const ListeningQuestion(
    audioPath: 'voices/cefr_a10010.wav',
    imagePath: 'images/cefr_a10010.png',
    englishText: 'What time is it now?',
  ),
];
